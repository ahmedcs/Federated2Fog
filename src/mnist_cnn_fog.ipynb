{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from arguments import Arguments\n",
    "from cnn import CNN\n",
    "from collections import defaultdict\n",
    "from numpy import array\n",
    "from numpy.random import permutation, randint\n",
    "import os\n",
    "import syft as sy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from distributor import get_cluster_sizes, get_fog_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setups\n",
    "args = Arguments()\n",
    "hook = sy.TorchHook(torch)\n",
    "USE_CUDA = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if USE_CUDA else {}\n",
    "kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ckpt_path = '../ckpts'\n",
    "dataset = 'mnist'\n",
    "clf_type = 'cnn'\n",
    "paradigm = 'fog'\n",
    "model_name = '{}_{}_{}'.format(dataset, clf_type, paradigm)\n",
    "init_path = os.path.join(ckpt_path, model_name, '.init')\n",
    "best_path = os.path.join(ckpt_path, model_name, '.best')\n",
    "stop_path = os.path.join(ckpt_path, model_name, '.stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_map, workers = get_fog_graph(hook, args.num_workers, args.num_clusters,\n",
    "                                 args.shuffle_workers, args.uniform_clusters)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "    .federate(workers),\n",
    "    batch_size=args.num_train, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.num_test, shuffle=True, **kwargs)\n",
    "\n",
    "for data, target in train_loader:\n",
    "    \n",
    "\n",
    "\n",
    "for data, target in test_loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        total += data.shape[0]\n",
    "        model.send(data.location)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size,\n",
    "                len(train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# Test\n",
    "def test(args, model, device, test_loader, best):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    if accuracy > best:\n",
    "        best = accuracy\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) ==> {:.2f}%'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100.*accuracy, 100.*best))\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best = 0\n",
    "\n",
    "# Fire the engines\n",
    "model = CNN().to(device)\n",
    "if args.load_init:\n",
    "    model.load_state_dict(torch.load(init_path))\n",
    "    print('Load init: {}'.format(init_path))\n",
    "elif args.save_init:\n",
    "    torch.save(model.state_dict(), init_path)\n",
    "    print('Save init: {}'.format(init_path))\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    best = test(args, model, device, test_loader, best)\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print('Model best: {}\\n'.format(best_path))\n",
    "    \n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), stop_path)\n",
    "    print('Model stop: {}'.format(stop_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "mnist_cnn_fog.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
