{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from arguments import Arguments\n",
    "from cnn import CNN\n",
    "from collections import defaultdict\n",
    "from distributor import get_cluster_sizes, get_distributed_data, get_fog_graph\n",
    "from train import fog_train as train\n",
    "from numpy import array\n",
    "from numpy.random import permutation, randint\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import syft as sy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setups\n",
    "args = Arguments()\n",
    "hook = sy.TorchHook(torch)\n",
    "USE_CUDA = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if USE_CUDA else {}\n",
    "kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ckpt_path = '../ckpts'\n",
    "dataset = 'mnist'\n",
    "clf_type = 'cnn'\n",
    "paradigm = 'fog'\n",
    "model_name = '{}_{}_{}'.format(dataset, clf_type, paradigm)\n",
    "init_path = os.path.join(ckpt_path, 'mnist_cnn_fl.init')\n",
    "best_path = os.path.join(ckpt_path, model_name + '.best')\n",
    "stop_path = os.path.join(ckpt_path, model_name + '.stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([60000, 1, 28, 28])\n",
      "y_train: torch.Size([60000])\n",
      "X_test: torch.Size([10000, 1, 28, 28])\n",
      "y_test: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.num_train, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "for data, target in train_loader:\n",
    "    X_train = data\n",
    "    y_train = target\n",
    "\n",
    "for data, target in test_loader:\n",
    "    X_test = data\n",
    "    y_test = target\n",
    "\n",
    "print('X_train: {}'.format(X_train.shape))\n",
    "print('y_train: {}'.format(y_train.shape))\n",
    "\n",
    "print('X_test: {}'.format(X_test.shape))\n",
    "print('y_test: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1_W0': ['L0_W20', 'L0_W28', 'L0_W42', 'L0_W41', 'L0_W29'],\n",
       " 'L1_W1': ['L0_W36', 'L0_W22', 'L0_W13', 'L0_W12', 'L0_W30'],\n",
       " 'L1_W2': ['L0_W34', 'L0_W18', 'L0_W15', 'L0_W43', 'L0_W24'],\n",
       " 'L1_W3': ['L0_W8', 'L0_W16', 'L0_W44', 'L0_W46', 'L0_W11'],\n",
       " 'L1_W4': ['L0_W37', 'L0_W48', 'L0_W5', 'L0_W7', 'L0_W9'],\n",
       " 'L1_W5': ['L0_W3', 'L0_W26', 'L0_W35', 'L0_W23', 'L0_W47'],\n",
       " 'L1_W6': ['L0_W17', 'L0_W25', 'L0_W2', 'L0_W10', 'L0_W40'],\n",
       " 'L1_W7': ['L0_W21', 'L0_W1', 'L0_W19', 'L0_W38', 'L0_W0'],\n",
       " 'L1_W8': ['L0_W27', 'L0_W4', 'L0_W31', 'L0_W6', 'L0_W14'],\n",
       " 'L1_W9': ['L0_W45', 'L0_W32', 'L0_W39', 'L0_W49', 'L0_W33'],\n",
       " 'L2_W0': ['L1_W3', 'L1_W0'],\n",
       " 'L2_W1': ['L1_W7', 'L1_W8'],\n",
       " 'L2_W2': ['L1_W5', 'L1_W9'],\n",
       " 'L2_W3': ['L1_W2', 'L1_W6'],\n",
       " 'L2_W4': ['L1_W1', 'L1_W4'],\n",
       " 'L3_W0': ['L2_W1', 'L2_W4', 'L2_W2'],\n",
       " 'L3_W1': ['L2_W0', 'L2_W3'],\n",
       " 'L4_W0': ['L3_W1', 'L3_W0']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare graph and data\n",
    "fog_graph, workers = get_fog_graph(hook, args.num_workers, args.num_clusters,\n",
    "                                 args.shuffle_workers, args.uniform_clusters)\n",
    "X_trains, y_trains = get_distributed_data(X_train, y_train, args.num_workers)\n",
    "fog_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(args, model, graph, nodes, X_trains, y_trains, device, epoch):\n",
    "    model.train()\n",
    "\n",
    "    total = args.num_train\n",
    "\n",
    "    worker_data = {}\n",
    "    worker_targets = {}\n",
    "    worker_num_samples = {}\n",
    "    worker_models = {}\n",
    "    worker_optims = {}\n",
    "    worker_losses = {}\n",
    "    \n",
    "    # send data, model to workers\n",
    "    # setup optimizer for each worker\n",
    "\n",
    "    workers = [_ for _ in nodes.keys() if 'L0' in _]\n",
    "    for w, x, y in zip(workers, X_trains, y_trains):\n",
    "        worker_data[w] = x.send(nodes[w])\n",
    "        worker_targets[w] = y.send(nodes[w])\n",
    "        worker_num_samples[w] = x.shape[0]\n",
    "        \n",
    "    total = 0\n",
    "\n",
    "    for w in workers:\n",
    "        worker_models[w] = model.copy().send(nodes[w])\n",
    "        worker_optims[w] = optim.SGD(params=worker_models[w].parameters(), lr=args.lr)\n",
    "\n",
    "        data = worker_data[w]\n",
    "        target = worker_targets[w]\n",
    "        total += data.shape[0]\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        worker_optims[w].zero_grad()\n",
    "        output = worker_models[w](data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        worker_optims[w].step()\n",
    "        worker_losses[w] = loss.get().data\n",
    "\n",
    "    for l in range(1, len(args.num_clusters)+1):\n",
    "        aggregators = [_ for _ in nodes.keys() if 'L{}'.format(l) in _]\n",
    "        for a in aggregators:\n",
    "            worker_models[a] = model.copy().send(nodes[a])\n",
    "            worker_num_samples[a] = 1\n",
    "            children = fog_graph[a]\n",
    "\n",
    "            for child in children:\n",
    "                worker_models[child].move(nodes[a])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                weighted_models = [get_model_weights(worker_models[_], worker_num_samples[_])for _ in children]\n",
    "                model_sum = weighted_models[0]\n",
    "                for m in weighted_models[1:]:\n",
    "                    model_sum = add_model_weights(model_sum, m)\n",
    "                worker_models[a].load_state_dict(model_sum)\n",
    "\n",
    "    assert len(aggregators) == 1\n",
    "    master = get_model_weights(worker_models[aggregators[0]].get(), 1/args.num_train)\n",
    "    model.load_state_dict(master)\n",
    "\n",
    "    loss = array([_.cpu().numpy() for dump, _ in worker_losses.items()])\n",
    "    print('Train Epoch: {} \\tLoss: {:.6f} +- {:.6f}'.format(\n",
    "        epoch,\n",
    "        loss.mean(), loss.std()\n",
    "    ))\n",
    "\n",
    "\n",
    "# Test\n",
    "def test(args, model, device, test_loader, best):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    if accuracy > best:\n",
    "        best = accuracy\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) ==> {:.2f}%'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100.*accuracy, 100.*best))\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load init: ../ckpts/mnist_cnn_fl.init\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "# Fire the engines\n",
    "model = CNN().to(device)\n",
    "if args.load_init:\n",
    "    model.load_state_dict(torch.load(init_path))\n",
    "    print('Load init: {}'.format(init_path))\n",
    "elif args.save_init:\n",
    "    torch.save(model.state_dict(), init_path)\n",
    "    print('Save init: {}'.format(init_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 2.306139 +- 0.000868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2681, Accuracy: 2650/10000 (26.50%) ==> 26.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 \tLoss: 2.268448 +- 0.000971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2310, Accuracy: 4168/10000 (41.68%) ==> 41.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 \tLoss: 2.232030 +- 0.001229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1905, Accuracy: 5562/10000 (55.62%) ==> 55.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 \tLoss: 2.192104 +- 0.001600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1421, Accuracy: 6443/10000 (64.43%) ==> 64.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 \tLoss: 2.144583 +- 0.002072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0814, Accuracy: 6920/10000 (69.20%) ==> 69.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 \tLoss: 2.085014 +- 0.002663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0029, Accuracy: 7220/10000 (72.20%) ==> 72.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 \tLoss: 2.008063 +- 0.003426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9001, Accuracy: 7369/10000 (73.69%) ==> 73.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 \tLoss: 1.907259 +- 0.004428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7661, Accuracy: 7437/10000 (74.37%) ==> 74.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 \tLoss: 1.775962 +- 0.005710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.5957, Accuracy: 7637/10000 (76.37%) ==> 76.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 \tLoss: 1.609271 +- 0.007225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3928, Accuracy: 7879/10000 (78.79%) ==> 78.79%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, fog_graph, workers, X_trains, y_trains, device, epoch)\n",
    "    best = test(args, model, device, test_loader, best)\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print('Model best: {}\\n'.format(best_path))\n",
    "    \n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), stop_path)\n",
    "    print('Model stop: {}'.format(stop_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "mnist_cnn_fog.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
